{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UrMogYNs-RbX"
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pJs4iEcqyQm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.applications import VGG19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubvGsbAc-Z9V"
   },
   "source": [
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsLXlnkuHj8A"
   },
   "outputs": [],
   "source": [
    "style_path = 'style4.jpg'\n",
    "content_path = 'eye.jpg'\n",
    "\n",
    "morphed_img = content_path[:-4] + '_' + style_path\n",
    "\n",
    "style_path = '.../style/' + style_path\n",
    "content_path = '.../content/' + content_path\n",
    "output_path = '.../stylized/'\n",
    "\n",
    "content_layers = ['block5_conv2']\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1', \n",
    "                'block4_conv1', \n",
    "                'block5_conv1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UDaM2ZGJ-u5V"
   },
   "source": [
    "# image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_CDmMDAJSR_"
   },
   "outputs": [],
   "source": [
    "# max dims 512 x 512\n",
    "# rescale style image to content dimensions\n",
    "def rescale_image(img_path, dims = None):\n",
    "  dim = 512\n",
    "  img = cv2.imread(img_path)\n",
    "  a, b, _ = img.shape\n",
    "  a, b = min(a,dim), min(b,dim)\n",
    "  if(dims != None):\n",
    "    a, b = dims[0], dims[1]\n",
    "  x = cv2.resize(img, (a, b))\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLfYzS_R8Bt_"
   },
   "outputs": [],
   "source": [
    "# scale tensor values to lie in range [0, 1]\n",
    "# this though not necessary speeds up learning\n",
    "def image_to_tensor(x):\n",
    "  x = x / 255.0\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFntJh54Llt2"
   },
   "outputs": [],
   "source": [
    "def clip(image):\n",
    "  return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCzBEYqE3K8y"
   },
   "outputs": [],
   "source": [
    "def deprocess_image(tensor):\n",
    "  x = np.array(tensor) * 255.0\n",
    "  x = x[0]\n",
    "  x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "  plt.imshow(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9N3m9D24-6A0"
   },
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJw0qqVrGjHo"
   },
   "outputs": [],
   "source": [
    "def vgg_layers(layer_names):\n",
    "  vgg = VGG19(include_top=False, weights='imagenet')\n",
    "  vgg.trainable = False\n",
    "  outputs = []\n",
    "\n",
    "  outputs = [vgg.get_layer(name).output for name in layer_names]\n",
    "  \n",
    "  model = tf.keras.Model([vgg.input], outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0rm-0o2YGLN"
   },
   "outputs": [],
   "source": [
    "class ModelClass(tf.keras.models.Model):\n",
    "  def __init__(self, all_layers):\n",
    "    super(ModelClass, self).__init__()\n",
    "    self.vgg =  vgg_layers(all_layers)\n",
    "    self.all_layers = all_layers\n",
    "    self.vgg.trainable = False\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # inputs in form of (1, None, None, 3) tensor\n",
    "    # preprocessing is a part of the model\n",
    "    inputs = inputs * 255.0\n",
    "    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
    "    outputs = self.vgg(preprocessed_input)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0SZGN0y_FXv"
   },
   "source": [
    "# losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCgadEvgA9do"
   },
   "outputs": [],
   "source": [
    "def compute_content_cost(a_C, a_G):\n",
    "  m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "  J_content = tf.reduce_sum(tf.square(tf.subtract(a_C,a_G)))/(4*n_C*n_H*n_W)\n",
    "\n",
    "  return J_content\n",
    "\n",
    "def gram_matrix(A):\n",
    "  GA = tf.matmul(A,tf.transpose(A,[1,0]))\n",
    "\n",
    "  return GA\n",
    "\n",
    "def compute_layer_style_cost(a_S, a_G):\n",
    "  m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "  a_S = tf.transpose(tf.reshape(a_S, [n_H*n_W, n_C]), [1,0])\n",
    "  a_G = tf.transpose(tf.reshape(a_G, [n_H*n_W, n_C]), [1,0])\n",
    "  GS = gram_matrix(a_S)\n",
    "  GG = gram_matrix(a_G)\n",
    "  J_style_layer = tf.reduce_sum(tf.square(tf.subtract(GS,GG)))/(4*(n_C*n_H*n_W)**2)\n",
    "\n",
    "  return J_style_layer\n",
    "\n",
    "def total_cost(content_outputs, style_outputs, outputs, alpha = 10000, beta = 3):\n",
    "  content = compute_content_cost(content_outputs, outputs[0])\n",
    "  style = 0\n",
    "\n",
    "  for i in range(1,len(outputs)):\n",
    "    style = style + 0.2*compute_layer_style_cost(style_outputs[i-1], outputs[i])\n",
    "  \n",
    "  return content, style, beta*style + content*alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-dLZo4RIll5"
   },
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mquX-EWGH39g"
   },
   "outputs": [],
   "source": [
    "def StyleTransfer(style_path, content_path):\n",
    "  content_image = rescale_image(content_path)\n",
    "  style_image = rescale_image(style_path, dims=content_image.shape)\n",
    "\n",
    "  content_image = image_to_tensor(content_image)\n",
    "  style_image = image_to_tensor(style_image)\n",
    "\n",
    "  style_extractor = ModelClass(style_layers)\n",
    "  style_outputs = style_extractor(style_image)\n",
    "\n",
    "  content_extractor = ModelClass(content_layers)\n",
    "  content_outputs = content_extractor(content_image)\n",
    "\n",
    "  # actual model\n",
    "  model = ModelClass(content_layers + style_layers)\n",
    "  model.trainable = False\n",
    "\n",
    "  img = tf.Variable(content_image)\n",
    "  optimizer = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
    "\n",
    "  def train_step(image):\n",
    "    with tf.GradientTape() as tape:\n",
    "      outputs = model(image)\n",
    "      content_loss, style_loss, loss = total_cost(content_outputs, style_outputs, outputs)\n",
    "    grads = tape.gradient(loss, image)\n",
    "    optimizer.apply_gradients([(grads, image)])\n",
    "    image.assign(clip(image))\n",
    "    return content_loss, style_loss, loss\n",
    "  \n",
    "  epochs = 10\n",
    "  steps_per_epoch = 100\n",
    "\n",
    "  content_loss = np.zeros([epochs*steps_per_epoch])\n",
    "  style_loss = np.zeros([epochs*steps_per_epoch])\n",
    "  loss = np.zeros([epochs*steps_per_epoch])\n",
    "  step = 0\n",
    "\n",
    "  for n in range(epochs):\n",
    "    for m in range(steps_per_epoch):\n",
    "      content_loss[step], style_loss[step], loss[step] = train_step(img)\n",
    "      step += 1\n",
    "      print(\".\", end='')\n",
    "    print(\"Train step: \" + str(step))\n",
    "\n",
    "  plt.plot(content_loss, label = 'content_loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  plt.plot(style_loss, label = 'style_loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  plt.plot(loss, label = 'loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  final_img = deprocess_image(img.value())\n",
    "  return final_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6lb7LdInIsxp"
   },
   "source": [
    "# execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89205,
     "status": "ok",
     "timestamp": 1589732107686,
     "user": {
      "displayName": "Ranajay Medya",
      "photoUrl": "",
      "userId": "02160689287509861187"
     },
     "user_tz": -330
    },
    "id": "ZxTfjufhOu1s",
    "outputId": "756fc8bd-0661-4499-80fd-8003c1605fe7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run on colab gpu\n",
    "with tf.device('/gpu:0'):\n",
    "  image = StyleTransfer(style_path, content_path)\n",
    "  output_path = output_path + morphed_img\n",
    "  cv2.imwrite(output_path, image)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP6k3ovjESZlXeBeNgSAxQk",
   "collapsed_sections": [],
   "mount_file_id": "1j8tOjiWcC1WmZXgmyrLNbh5K1GuN-KtA",
   "name": "NStyle.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
